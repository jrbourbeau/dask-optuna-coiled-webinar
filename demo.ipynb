{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Optuna hyperparameter optimization with Dask\n",
    "\n",
    "<img src=\"optuna-logo.jpg\"\n",
    "     width=\"35%\"\n",
    "     alt=\"Optuna logo\">\n",
    "<img src=\"dask-logo.svg\"\n",
    "     width=\"35%\"\n",
    "     alt=\"Dask logo\">\n",
    "\n",
    "[Optuna](https://optuna.org/) and [Dask](https://dask.org) are popular Python libraries for hyperparameter optimization and parallel computing, respectively. This notebook walks through a workload which uses [Dask-Optuna](https://jrbourbeau.github.io/dask-optuna/), a library for integrating Dask and Optuna, to optimize an [XGBoost](https://xgboost.readthedocs.io/en/latest/) classification model in parallel across a Dask cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Workload\n",
    "\n",
    "## Step 1: Define an objective function\n",
    "\n",
    "Below is a snippet which uses Optuna to optimize several hyperparameters for an XGBoost classifier trained on the [breast cancer dataset](https://scikit-learn.org/stable/datasets/index.html#breast-cancer-wisconsin-diagnostic-dataset).\n",
    "\n",
    "There is no Dask-specific code here. This is exactly the same code you would write if you were to run Optuna on your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "def objective(trial):\n",
    "    # Load our dataset\n",
    "    X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    # Get set of hyperparameters\n",
    "    param = {\n",
    "        \"silent\": 1,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"dart\"]),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 9),\n",
    "        \"eta\": trial.suggest_float(\"eta\", 1e-8, 1.0, log=True),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True),\n",
    "        \"grow_policy\": trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"]),\n",
    "    }\n",
    "\n",
    "    # Train XGBoost model and get predeictions\n",
    "    bst = xgb.train(param, dtrain)\n",
    "    preds = bst.predict(dtest)\n",
    "\n",
    "    # Compute and return model accuracy\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_test, pred_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create a Dask cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll use [Coiled](https://coiled.io) to create a remote Dask cluster on AWS. \n",
    "\n",
    "**Note:** Dask-Optuna work with _any_ Dask cluster, we're just using Coiled here because it's a conveient way for anyone to spin up a remote Dask cluster. For more information on Coiled, see the [Coiled documentation](https://docs.coiled.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Cluster. This takes about a minute ...Checking environment images\n",
      "Valid environment image found\n",
      "CPU times: user 1.17 s, sys: 296 ms, total: 1.47 s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Use coiled to create a Dask cluster on AWS\n",
    "import coiled\n",
    "\n",
    "cluster = coiled.Cluster(\n",
    "    n_workers=10, \n",
    "    software=\"examples/optuna-xgboost\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"dask-cluster.svg\"\n",
    "     width=\"75%\"\n",
    "     alt=\"Dask cluster\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tls://ec2-18-216-150-48.us-east-2.compute.amazonaws.com:8786</li>\n",
       "  <li><b>Dashboard: </b><a href='http://ec2-18-216-150-48.us-east-2.compute.amazonaws.com:8787' target='_blank'>http://ec2-18-216-150-48.us-east-2.compute.amazonaws.com:8787</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>10</li>\n",
       "  <li><b>Cores: </b>40</li>\n",
       "  <li><b>Memory: </b>171.80 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tls://10.2.12.88:8786' processes=10 threads=40, memory=171.80 GB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect my local machine to the remote cluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(cluster)\n",
    "client.wait_for_workers(10)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☝️ Don't forget to check on the Dask dashboard!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run optimization trials in parallel\n",
    "\n",
    "Dask-Optuna leverages Optuna’s existing distributed optimization capabilities to run optimization trials in parallel on a Dask cluster. It does this by providing a Dask-compatible `dask_optuna.DaskStorage` storage class which wraps an Optuna storage class (e.g. Optuna’s in-memory or sqlite storage) and can be used directly by Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import dask_optuna\n",
    "import joblib\n",
    "\n",
    "# Create an Optuna study using a Dask-compatible Optuna storage class\n",
    "storage = dask_optuna.DaskStorage()\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    storage=storage,\n",
    ")\n",
    "\n",
    "# Run 200 optimizations trial on our cluster\n",
    "with joblib.parallel_backend(\"dask\"):\n",
    "    study.optimize(objective, n_trials=200, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster': 'gbtree',\n",
       " 'lambda': 2.2958926213388737e-05,\n",
       " 'alpha': 0.0024442753560806082,\n",
       " 'max_depth': 7,\n",
       " 'eta': 0.2593902003279806,\n",
       " 'gamma': 0.01747764804032886,\n",
       " 'grow_policy': 'depthwise'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with that, you’re able to run distributed hyperparameter optimizations using Dask and Optuna!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Dask-Optuna helps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduces setup\n",
    "\n",
    "Dask-Optuna helps reduce the setup required when using persistent storage to back an Optuna study (e.g. sqlite databse). It does so by creating a single storage object on the scheduler which is accessible all workers in a Dask cluster, instead of the user needing to set up a storage object which is globally accessible across the entire cluster.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wraps Optuna's in-memory storage\n",
    "storage_1 = dask_optuna.DaskStorage()\n",
    "\n",
    "# Wraps Optuna's SQLite DB storage\n",
    "storage_2 = dask_optuna.DaskStorage(\"sqlite:///example.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The underlying Optuna storage object lives on the cluster’s scheduler and any method calls on the `DaskStorage` instance results in the same method being called on the underlying Optuna storage object.\n",
    "\n",
    "**NOTE**: there are other totally valid approaches parallelizing Optuna. For example, here's a nice example of running Optuna on Kubernetes https://github.com/optuna/optuna/tree/master/examples/kubernetes. Each method has it's own relative pros and cons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extends Optuna’s `InMemoryStorage` to multiple processes\n",
    "\n",
    "Helps extend Optuna’s `InMemoryStorage` class to run across multiple processes. This is important when using remote workers in a Dask cluster or situations where Python’s GIL leads to less-than-ideal parallelization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking ahead\n",
    "\n",
    "We're currently working with the Optuna developers to include Dask-Optuna's functionality directly into Optuna.\n",
    "This will help facilitate better integration between Dask and Optuna 🎉"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
